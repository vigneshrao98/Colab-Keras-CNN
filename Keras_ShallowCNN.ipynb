{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_ShallowCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/vigneshrao98/Colab-Keras-CNN/blob/master/Keras_ShallowCNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "3cfE2NlJ7PNd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "Welcome! This is a Google Colab notebook. \n",
        "\n",
        "You can rename this notebook by clicking on 'name.ipynb' above.\n",
        "In this notebook you can find out how to make and train a simple keras model using the Colab's free K80 gpu!\n",
        "\n",
        "#Setting the runtime\n",
        "To use GPU accelerated runtime, just follow \n",
        "\n",
        "*Runtime > change runtime type > and select GPU as hardware exelerator*\n",
        "\n",
        "*Additonaly you must have noticed you can also chose which version of python you want to compile in!*\n"
      ]
    },
    {
      "metadata": {
        "id": "q0Agr_IM9Lju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#The Setup\n",
        "\n",
        "You will need to do the following to steps to instal te required libraries and perform authorisation-"
      ]
    },
    {
      "metadata": {
        "id": "34Ss0zAx9dhw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A2wwjnJm9jeI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Click the link, copy verification code and paste it to text box.\n",
        "This will complete the authorisation!\n",
        "\n",
        "Now you will mount your Google Drive to make it work with colab.\n",
        "\n",
        "Exectue the following code-"
      ]
    },
    {
      "metadata": {
        "id": "3nf5Xbht95aN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dVSCNlsD-EtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#The Directories\n",
        "You will often need to upload data that you want to use while executing or training like a  `Utility file` or `Training/Test data`.\n",
        "\n",
        "This import will get the required files for doing so-"
      ]
    },
    {
      "metadata": {
        "id": "FzLd6ws4-9hf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15RB6pO-_Amf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This line will list the files in your directory-"
      ]
    },
    {
      "metadata": {
        "id": "9RM0iFc7_HtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "111f02cf-3a82-4063-ed50-83522d6f5bc3"
      },
      "cell_type": "code",
      "source": [
        "files.os.listdir()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datalab',\n",
              " 'cifar-10-batches-py',\n",
              " '.config',\n",
              " 'distutils.py',\n",
              " 'distutils (1).py',\n",
              " '.cache',\n",
              " 'Transfer-Learning-in-keras---custom-data',\n",
              " '.forever',\n",
              " '.local',\n",
              " '__pycache__',\n",
              " 'Parameters.py',\n",
              " 'distutils3.py',\n",
              " '.ipython',\n",
              " '.keras',\n",
              " '.nv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Aog9i_YP_MiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This will let you upload files-"
      ]
    },
    {
      "metadata": {
        "id": "CjIQrTYy_STq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "8e421641-eb23-4920-8cce-850641bb50c0"
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63b259460c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NDazcNLz_Mnj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And this for downloading files (replace file-name with the required file name) -"
      ]
    },
    {
      "metadata": {
        "id": "c7yti8D__X2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('file-name')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlnpOqGD_reK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we are done with the basics lets get started on building the model. But first lets install the Keras library-"
      ]
    },
    {
      "metadata": {
        "id": "67wA2gOg_116",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FK-4lemXKEzq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Simple CNN on the CIFAR-10 dataset\n",
        "Following is a implementation of Convolutional Neural Networks in Keras framework. It is a shallow network having only 4 Conv, 2 MaxPool and 2 Fully connected dense layers. As the model complexity is low, regularization is kept to a minimum. "
      ]
    },
    {
      "metadata": {
        "id": "NWlzhwN9AzdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For implementing the model we will need a few utility functions present in a Utility file.\n",
        "\n",
        "We will need to upload it to the directory by following the steps given above for uploading. The file *distutils.py* is te one needed to be uploaded and it  is available on the Github repo.\n",
        "Link:\n",
        "\n",
        "This will help you understand how uploading works on Colab :D"
      ]
    },
    {
      "metadata": {
        "id": "0IUhSo-5HUEx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "25e787f5-6746-4804-890e-51176299b302"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-888bcd20-4b14-42d7-b4fa-f168b624a5ca\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-888bcd20-4b14-42d7-b4fa-f168b624a5ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving utils.py to utils.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'utils.py': b'#from sklearn.datasets import fetch_mldata\\r\\nfrom sklearn.preprocessing import OneHotEncoder\\r\\nfrom matplotlib import pyplot\\r\\nfrom scipy.misc import toimage\\r\\n#from sklearn.model_selection import train_test_split\\r\\nfrom urllib.request import urlretrieve\\r\\nfrom keras.preprocessing.image import ImageDataGenerator\\r\\nimport numpy as np\\r\\nimport os\\r\\nimport tarfile\\r\\nimport pickle\\r\\n\\r\\ndef lrScheduler(epoch):\\r\\n    lrate = 0.001\\r\\n    if epoch > 75:\\r\\n        lrate = 0.0005\\r\\n    elif epoch > 100:\\r\\n        lrate = 0.0003        \\r\\n    return lrate\\r\\n\\r\\ndef displayImg(X):\\r\\n    pyplot.figure(1)\\r\\n    k = 0\\r\\n    for i in range(0,4):\\r\\n        for j in range(0,4):\\r\\n            pyplot.subplot2grid((4,4),(i,j))\\r\\n            pyplot.imshow(toimage(X[k]))\\r\\n            k = k+1\\r\\n    # show the plot\\r\\n    pyplot.show()\\r\\n\\r\\ndef unPickle(src):\\r\\n    data = pickle.load(open(src, \\'rb\\'), encoding=\\'latin1\\')\\r\\n    return data\\r\\n\\r\\ndef downloadDataset(link):\\r\\n    print (\\'Downloading Dataset CIFAR\\')\\r\\n    fname, h = urlretrieve(link, \\'./delete.me\\')\\r\\n    with tarfile.open(fname) as tar:\\r\\n            tar.extractall()\\r\\n    print (\\'Preparing train and test sets\\')\\r\\n    train_list = [unPickle(\\'./cifar-10-batches-py/data_batch_{0}\\'.format(i + 1)) for i in range(5)]\\r\\n    x_train = np.concatenate([t[\\'data\\'] for t in train_list])\\r\\n    y_train = np.concatenate([t[\\'labels\\'] for t in train_list])       \\r\\n    print (\\'Preparing test set...\\')\\r\\n    tst = unPickle(\\'./cifar-10-batches-py/test_batch\\')\\r\\n    x_test = tst[\\'data\\']\\r\\n    y_test = np.asarray(tst[\\'labels\\'])\\r\\n    print (\\'Done.\\')\\r\\n    os.remove(fname)\\r\\n    return x_train, x_test, y_train, y_test\\r\\n\\r\\ndef getCifarDataset(): \\r\\n    x_train, x_test, y_train, y_test = downloadDataset(\"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\")\\r\\n    \\r\\n    \\r\\n    # Reshape\\r\\n    x_train = x_train.reshape(-1, 3, 32, 32)\\r\\n    x_test = x_test.reshape(-1, 3, 32, 32)\\r\\n    # Make channel last\\r\\n    x_train = np.swapaxes(x_train, 1, 3)\\r\\n    x_test = np.swapaxes(x_test, 1, 3) \\r\\n    #Normalizing pixel densities\\r\\n    \\r\\n    x_train = x_train/255\\r\\n    x_test = x_test/255 \\r\\n    # One Hot Encoding for y\\r\\n    y_train = np.expand_dims(y_train, axis=-1)\\r\\n    y_test = np.expand_dims(y_test, axis=-1)\\r\\n    enc = OneHotEncoder(categorical_features=\\'all\\')\\r\\n    fit = enc.fit(y_train)\\r\\n    y_train = fit.transform(y_train).toarray()\\r\\n    y_test = fit.transform(y_test).toarray()\\r\\n    # Set datatypes\\r\\n    x_train = x_train.astype(np.float32)\\r\\n    x_test = x_test.astype(np.float32)\\r\\n    y_train = y_train.astype(np.int32)\\r\\n    y_test = y_test.astype(np.int32)\\r\\n\\r\\n    return x_train, x_test, y_train, y_test\\r\\n\\r\\ndef augmentImgs(x):\\r\\n    sample = ImageDataGenerator(\\r\\n    rotation_range=15,\\r\\n    width_shift_range=0.1,\\r\\n    height_shift_range=0.1,\\r\\n    horizontal_flip=True,\\r\\n    )\\r\\n    sample.fit(x)\\r\\n    return sample\\r\\n\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "bVSB8glKBnqE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once you are done with uploading the files you can start with importing the required libraries-"
      ]
    },
    {
      "metadata": {
        "id": "Q2C2g21zseoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense\n",
        "from keras import regularizers\n",
        "from keras.optimizers import rmsprop,SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from utils import getCifarDataset\n",
        "\n",
        "#Hyperparameters\n",
        "EPOCHS = 10\n",
        "BATCHSIZE = 64\n",
        "LR = 0.01\n",
        "MOMENTUM = 0.9\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AXI0eeUBzqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will download the CIFAR-10 dataset and get it into training and testing files!\n",
        "\n",
        "Feel free to check out how function *getCifarDataset( )* works by checking it out in *distutils.py*"
      ]
    },
    {
      "metadata": {
        "id": "6J1jXMmRsoYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "d6eccfe9-871f-4eed-cf95-6664f642a919"
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = getCifarDataset()\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Dataset CIFAR\n",
            "Preparing train and test sets\n",
            "Preparing test set...\n",
            "Done.\n",
            "(50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 10) (10000, 10)\n",
            "float32 float32 int32 int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6eeLVSQ8CTsQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's define the model-"
      ]
    },
    {
      "metadata": {
        "id": "uWxanUkKswmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def createModel():\n",
        "  model = Sequential()\n",
        "    \n",
        "  model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(Conv2D(50, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(100, kernel_size=(3, 3), padding='same', activation='relu'))    \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Y7cqnI_Ccc5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Initializing the model-"
      ]
    },
    {
      "metadata": {
        "id": "BoZNKM6Ys025",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mod = createModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXAXCPemCkio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A funtion to compile the model-"
      ]
    },
    {
      "metadata": {
        "id": "i45K7Mcps06I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compile_model(m):\n",
        "    m.compile(\n",
        "        loss = \"categorical_crossentropy\",\n",
        "        optimizer = SGD(LR, MOMENTUM),\n",
        "        metrics = ['accuracy'])\n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lw9DO3rTCuCQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compiling the model-"
      ]
    },
    {
      "metadata": {
        "id": "dgRHeMlSs0_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = compile_model(mod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQMIaCwjCwmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fitting the model to the training set (EPOCHS, BATCHSIZE are hyperparametersdefined during the imports) -"
      ]
    },
    {
      "metadata": {
        "id": "2eMmHpqHs1Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "4ed824b6-e888-4ffd-be44-4fbdf8737963"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=BATCHSIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 40s 809us/step - loss: 1.8551 - acc: 0.3213\n",
            "Epoch 2/10\n",
            "23744/50000 [=============>................] - ETA: 19s - loss: 1.4504 - acc: 0.4744"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 37s 735us/step - loss: 1.3814 - acc: 0.5005\n",
            "Epoch 3/10\n",
            "40448/50000 [=======================>......] - ETA: 6s - loss: 1.1608 - acc: 0.5877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 37s 733us/step - loss: 1.1457 - acc: 0.5929\n",
            "Epoch 4/10\n",
            "48448/50000 [============================>.] - ETA: 1s - loss: 0.9986 - acc: 0.6455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 37s 743us/step - loss: 0.9949 - acc: 0.6470\n",
            "Epoch 5/10\n",
            "49728/50000 [============================>.] - ETA: 0s - loss: 0.8824 - acc: 0.6895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 38s 750us/step - loss: 0.8819 - acc: 0.6897\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.7960 - acc: 0.7186\n",
            "Epoch 7/10\n",
            "  640/50000 [..............................] - ETA: 35s - loss: 0.6401 - acc: 0.7734"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 36s 726us/step - loss: 0.7261 - acc: 0.7435\n",
            "Epoch 8/10\n",
            "26560/50000 [==============>...............] - ETA: 18s - loss: 0.6588 - acc: 0.7681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 38s 760us/step - loss: 0.6627 - acc: 0.7668\n",
            "Epoch 9/10\n",
            "41472/50000 [=======================>......] - ETA: 6s - loss: 0.6060 - acc: 0.7843"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 37s 735us/step - loss: 0.6052 - acc: 0.7853\n",
            "Epoch 10/10\n",
            "48192/50000 [===========================>..] - ETA: 1s - loss: 0.5525 - acc: 0.8034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 37s 731us/step - loss: 0.5535 - acc: 0.8031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e2a88a438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "ZNmZljMQDTXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluating the model-"
      ]
    },
    {
      "metadata": {
        "id": "wQ1eqxpOs1Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9ef91288-a319-45c5-f0c2-8a8c0bbc5d4e"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 176us/step\n",
            "\n",
            "Test result: 77.070 loss: 0.661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYsKgArWDFgh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Saving the model as *model.h5* to directory-"
      ]
    },
    {
      "metadata": {
        "id": "gsZiDqGps1IH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "\n",
        "with open('model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "model.save_weights('model.h5')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbZUcjyJDZ6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can download the *model.h5* file-"
      ]
    },
    {
      "metadata": {
        "id": "XfKpJjfEs00A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OY4jVKr2E7Zj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Conclusion"
      ]
    },
    {
      "metadata": {
        "id": "MHoPx9ouDo2I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There you go! You have succefully compiled a keras CNN model using the free K80 gpu!\n",
        "\n",
        "This model was not a complex one ofcourse you have not utilised the full powers of the K80 gpu, \n",
        "\n",
        "feel free to check out my repository on making a more complex model to get a better test results on the CIFAR-10 dataset using and more regularization techniques and some data augmentation to increase the training set size!\n",
        "\n",
        "Here's the link:\n",
        "\n",
        "Thank you for checking out this tutorial! : )"
      ]
    }
  ]
}